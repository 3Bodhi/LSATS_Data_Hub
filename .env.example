# Authentication
## NOTE: ALL entered values should be contained in quoation marks "value"
# TeamDynamix
## Remove SB to run in Production.
TDX_BASE_URL = "https://teamdynamix.umich.edu/SBTDWebApi/api"
TDX_APP_ID = 48 #asset/CI App
## NOTE: SBTDWebApi in the URL is for Sandbox endpoints and Api Token creation. Remove SB in urls for production

## Authentication (choose one method, priority: BEID > Login > Token)
## Method 1: Admin service account (highest priority, auto-refresh)
# TDX_BEID =
# TDX_WEB_SERVICES_KEY =

## Method 2: Username/password login (auto-refresh, 24hr token lifetime)
# TDX_USERNAME =
# TDX_PASSWORD =

## Method 3: Static API token (legacy, no auto-refresh)
TDX_API_TOKEN = #api token from https://teamdynamix.umich.edu/SBTDWebApi/api/auth/loginsso

# Google
## Sheets
### Create a google project here: (https://developers.google.com/sheets/api/quickstart/python)
### and download credentials.json into the main project folder
CREDENTIALS_FILE = 'credentials.json'
SPREADSHEET_ID = #first section after "/spreadsheets/d/" in the url. stops usually at "/edit"
SHEET_NAME = 'March' # The actual sheet name, case sensitive. Usually a month, eg "March"

#AI
## Default: Ollama
AI_PROVIDER=ollama
AI_MODEL=gemma3:27b
AI_BASE_URL=http://localhost:11434
AI_TIMEOUT=120

## OpenAI
# AI_PROVIDER=openai
# AI_MODEL=gpt-3.5-turbo
# AI_API_KEY=your_openai_api_key_here
# AI_TIMEOUT=30

# For GPT-4 (more expensive but higher quality):
# AI_MODEL=gpt-4
# AI_MODEL=gpt-4-turbo

# PostgreSQL Database Connection
DATABASE_URL=postgresql://lsats_user:lsats_dev_password@localhost:5432/lsats_db
DB_HOST=localhost
DB_PORT=5432
DB_NAME=lsats_db
DB_USER=lsats_user
DB_PASSWORD=lsats_dev_password

# Production database (when you deploy later)
# DATABASE_URL=postgresql://lsats_user:secure_production_password@prod-db-server:5432/lsats_db

# Database Migration and Management
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30

# ==============================================================================
# DATA INGESTION CONFIGURATION
# ==============================================================================

# File paths for data sources
DATA_PATH=./data
LAB_MEMBERSHIPS_CSV=./data/lab_memberships.csv
REGIONS_CSV=./data/regions.csv

# Ingestion behavior settings
BATCH_SIZE=1000
SYNC_FREQUENCY=daily
DATA_QUALITY_THRESHOLD=0.7

# Source system priorities (higher number = more trusted)
# Used for master record reconciliation when sources conflict
TDX_PRIORITY=10
CSV_PRIORITY=8
LDAP_PRIORITY=9
MANUAL_PRIORITY=5

# ==============================================================================
# DEVELOPMENT AND DEBUGGING
# ==============================================================================

# Development database (use this for testing)
DEV_DATABASE_URL=postgresql://lsats_user:lsats_dev_password@localhost:5432/lsats_db_dev

# Logging configuration
LOG_LEVEL=INFO
LOG_FILE=./logs/lsats_database.log
ENABLE_SQL_LOGGING=false

# Feature flags for gradual rollout
ENABLE_DATABASE_INTEGRATION=true
ENABLE_MASTER_RECORD_CREATION=true
ENABLE_AUTO_RECONCILIATION=false

# ==============================================================================
# DOCKER COMPOSE OVERRIDES
# ==============================================================================

# pgAdmin Configuration (for database management UI)
PGADMIN_PASSWORD=admin

# Container resource limits
POSTGRES_SHARED_BUFFERS=256MB
POSTGRES_MAX_CONNECTIONS=100

# ==============================================================================
# DATA QUALITY AND MONITORING
# ==============================================================================

# Quality score thresholds
MIN_QUALITY_SCORE=0.5
HIGH_QUALITY_THRESHOLD=0.9

# Monitoring and alerting (future use)
ENABLE_SLACK_NOTIFICATIONS=false
SLACK_WEBHOOK_URL=
ALERT_ON_INGESTION_FAILURE=true
ALERT_ON_LOW_QUALITY_DATA=true

# Data retention policies
BRONZE_RETENTION_DAYS=365  # Keep raw data for one year
INGESTION_LOG_RETENTION_DAYS=90  # Keep ingestion logs for three months

# ==============================================================================
# TICKET QUEUE DAEMON CONFIGURATION
# ==============================================================================

# Report ID to monitor (get from TeamDynamix Report Builder)
DAEMON_REPORT_ID=1344

# Daemon behavior
DAEMON_INTERVAL=300  # Polling interval in seconds (300 = 5 minutes)
DAEMON_MODE=once  # 'once' or 'continuous'
DAEMON_DRY_RUN=false  # Set to true for testing without making changes

# Action configuration (can also use config.json file)
DAEMON_ACTION_COMMENT_TEXT="Hello World"
DAEMON_ACTION_IS_PRIVATE=false
